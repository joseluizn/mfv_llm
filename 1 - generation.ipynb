{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lewis/miniconda3/envs/eda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from llm_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authenticate with the APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=getpass(\"Enter API key: \"), transport='rest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_message = \"\"\"You're an artificial intelligence which reacts to vignettes on psychological scales.\n",
    "For instance, if an user asks you: How much do you agree with the following statement? '1. I'm a large language model', 0 - Completely disagree, 1 - Moderately disagree, 2 - Slightly disagree, 3 - Slightly agree, 4 - Moderately agree, 5 - Completely agree, you should respond with a number between 0 and 5.\n",
    "Your response SHOULD NOT contain the number's accompanying text. So, if you select '5', you should just return '1. 5', instead of '1. 5 - Completely agree'.\n",
    "DON'T explain your reasoning. I'm ONLY interested in your response to the scale.\n",
    "Make sure that the response falls within the boundaries of the question. For instance: 3 is NOT an acceptable answer to a question that should be answered with a 0 or a 1\n",
    "If an user asks multiple questions, you should respond with a list of numbers, one for each question.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading mfq info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./stimuli/mfq.json\") as f:\n",
    "    mfq = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading MFV prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the stimuli from mfv.json\n",
    "with open(\"./stimuli/mfv.json\") as f:\n",
    "    mfv_info = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading vignettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_vignettes = pd.read_html(mfv_info[\"vignettes_html\"])[0]\n",
    "original_vignettes[\"mfv_code\"] = mfv_info[\"validated_codes\"]\n",
    "\n",
    "# loading vignittes used in portuguese\n",
    "mfv_pt = pd.read_excel(\"stimuli/mfvignettes_pt.xlsx\", sheet_name=0)\n",
    "double_validated_codes = mfv_pt[\"MFV Code\"].to_list()\n",
    "foundations = mfv_pt[\"Foundation\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mfq_stimuli(randomize=False):\n",
    "    global mfq\n",
    "    if randomize is False:\n",
    "        return {\n",
    "            \"p1\": mfq[\"mfq_part1\"],\n",
    "            \"p2\": mfq[\"mfq_part2\"],\n",
    "            \"items1\": mfq[\"part1_item_key\"],\n",
    "            \"items2\": mfq[\"part2_item_key\"],\n",
    "        }\n",
    "    else:\n",
    "        # randomize the order of the items\n",
    "        p1, p1items = shuffle(mfq[\"part1_questions\"], mfq[\"part1_item_key\"])\n",
    "        p2, p2items = shuffle(mfq[\"part2_questions\"], mfq[\"part2_item_key\"])\n",
    "        # generate string with p1 with number at beginning of each line\n",
    "        p1 = \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(p1)])\n",
    "        p2 = \"\\n\".join([f\"{i+1+len(p1items)}. {q}\" for i, q in enumerate(p2)])\n",
    "        return {\"p1\": mfq[\"part1_header\"] + p1, \"p2\": mfq[\"part2_header\"] + p2, \"items1\": p1items, \"items2\": p2items}\n",
    "    \n",
    "def generate_mfv_stimuli(randomize=False):\n",
    "    global mfv_info\n",
    "    pre_mfv = mfv_info[\"pre_mfv\"]\n",
    "    if randomize is False:\n",
    "        numbered_vignettes = \"\\n\".join(\n",
    "            (\n",
    "                (original_vignettes.reset_index().index + 1).astype(str)\n",
    "                + \". \"\n",
    "                + original_vignettes[\"Scenario\"]\n",
    "            ).to_list()\n",
    "        )\n",
    "        mfv_prompt = pre_mfv + \"\\n\\n\" + numbered_vignettes\n",
    "        codes = original_vignettes[\"mfv_code\"].to_list()\n",
    "    else:\n",
    "        df = original_vignettes.sample(frac=1).copy()\n",
    "        numbered_vignettes = \"\\n\".join(\n",
    "            (\n",
    "                (df.reset_index().index + 1).astype(str)\n",
    "                + \". \"\n",
    "                + df[\"Scenario\"]\n",
    "            ).to_list()\n",
    "        )\n",
    "        mfv_prompt = pre_mfv + \"\\n\\n\" + numbered_vignettes\n",
    "        codes = df[\"mfv_code\"].to_list()\n",
    "    return {\n",
    "        \"prompt\": mfv_prompt,\n",
    "        \"mfv_codes\": codes,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation - MfVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_vignettes = pd.read_html(mfv_info[\"vignettes_html\"])[0]\n",
    "original_vignettes[\"mfv_code\"] = mfv_info[\"validated_codes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading vignittes used in portuguese\n",
    "mfv_pt = pd.read_excel(\"stimuli/mfvignettes_pt.xlsx\", sheet_name=0)\n",
    "double_validated_codes = mfv_pt[\"MFV Code\"].to_list()\n",
    "foundations = mfv_pt[\"Foundation\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintaining only validated in brazilian replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintaining only validated in brazilian replication\n",
    "original_vignettes.query(\"mfv_code in @double_validated_codes\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mfq(model, chat_history):\n",
    "    mfq_info = generate_mfq_stimuli(randomize=True)\n",
    "    mfq_part1 = mfq_info[\"p1\"]\n",
    "    mfq_part2 = mfq_info[\"p2\"]\n",
    "    chat_history.append({\"role\": \"user\", \"content\": mfq_part1})\n",
    "    part1_answer = model(chat_history)\n",
    "\n",
    "    chat_history.extend(\n",
    "        [\n",
    "            {\"role\": \"assistant\", \"content\": part1_answer},\n",
    "            {\"role\": \"user\", \"content\": mfq_part2},\n",
    "        ]\n",
    "    )\n",
    "    # if part1 is not none\n",
    "    if part1_answer:\n",
    "        part2_answer = model(chat_history)\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": part2_answer})\n",
    "    else:\n",
    "        part2_answer = None\n",
    "    return {\n",
    "        \"part1\": part1_answer,\n",
    "        \"part2\": part2_answer,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"part1_order\": mfq_info[\"items1\"],\n",
    "        \"part2_order\": mfq_info[\"items2\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def run_mfv(model, chat_history):\n",
    "    mfv_info = generate_mfv_stimuli(randomize=True)\n",
    "    mfv_prompt = mfv_info[\"prompt\"]\n",
    "    chat_history.append({\"role\": \"user\", \"content\": mfv_prompt})\n",
    "    mfv_answer = model(chat_history)\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": mfv_answer})\n",
    "    return {\n",
    "        \"mfv\": mfv_answer,\n",
    "        \"chat_history\": chat_history,\n",
    "        \"mfv_codes\": mfv_info[\"mfv_codes\"],\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_mfv_condition(model, agent_name, id, condition):\n",
    "    base_chat = [\n",
    "        {\"role\": \"system\", \"content\": role_message},\n",
    "    ]\n",
    "\n",
    "    chat_log = base_chat.copy()\n",
    "    if condition == \"qv\":\n",
    "        # call mfq\n",
    "        mfq_answer = run_mfq(model, chat_log)\n",
    "\n",
    "        # call mfv\n",
    "        mfv_answer = run_mfv(model, chat_log)\n",
    "    elif condition == \"vq\":\n",
    "        # call mfv\n",
    "        mfv_answer = run_mfv(model, chat_log)\n",
    "\n",
    "        # call mfq\n",
    "        mfq_answer = run_mfq(model, chat_log)\n",
    "    else:\n",
    "        raise ValueError(\"Condition must be 'qv' or 'vq'\")\n",
    "\n",
    "    # append to responses\n",
    "    return {\n",
    "        \"agent\": agent_name,\n",
    "        \"id\": id,\n",
    "        \"condition\": condition,\n",
    "        \"mfq\": mfq_answer,\n",
    "        \"mfv\": mfv_answer,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n, models):\n",
    "    today_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    general_results = list()\n",
    "    for agent, model in models.items():\n",
    "        results = list()\n",
    "        for i in range(n):\n",
    "            for condition in [\"qv\", \"vq\"]:\n",
    "                results.append(generate_mfv_condition(model, agent, i, condition))\n",
    "        fl = Path(f\"raw_data/{today_str}_{agent}.json\")\n",
    "        fl.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # check if file exists\n",
    "        if fl.exists():\n",
    "            with open(fl) as f:\n",
    "                old_results = json.load(f)\n",
    "            old_results.extend(results)\n",
    "            with open(fl, \"w\") as f:\n",
    "                json.dump(old_results, f)\n",
    "        else:\n",
    "            with open(fl, \"w\") as f:\n",
    "                json.dump(results, f)\n",
    "        general_results.extend(results)\n",
    "            \n",
    "    return general_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gemini Pro\": call_gemini,\n",
    "    # \"Llama 2 Chat 70b\": call_llama2, # removed llama due to unreliable results\n",
    "    \"Claude 2.1\": call_claude2_1,\n",
    "    \"GPT-4\": call_gpt4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 59\n",
    "run_size = 1\n",
    "its = n//run_size\n",
    "for i in range(its):\n",
    "    try:\n",
    "        r.extend(run_experiment(run_size, models))\n",
    "    except Exception as e:\n",
    "        print(f\"Error on iteration {i} of {its}\")\n",
    "        print(e)\n",
    "        # log error\n",
    "        with open(\"error_log_1.txt\", \"a+\") as f:\n",
    "            f.write(f\"Error on iteration {i} of {its}. {e}\")\n",
    "            f.write(\"\\n\")\n",
    "        continue\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove chat history from r before saving\n",
    "# for d in r:\n",
    "#     del d[\"mfq\"][\"chat_history\"]\n",
    "#     del d[\"mfv\"][\"chat_history\"]\n",
    "\n",
    "# with open(\"data/mfv_test.json\", \"w\") as f:\n",
    "#     json.dump(r, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
