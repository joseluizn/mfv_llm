{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "\n",
    "from helpers import vignettes_en, validated_codes\n",
    "from helpers import single_scenario_generation\n",
    "\n",
    "openai.api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('You see a man telling his girlfriend that she has to convert to his religion.',\n",
       "  503),\n",
       " ('You see a girl laughing at another student who forgot the lines at a school theatre play.',\n",
       "  111),\n",
       " ('You see a boy leaving a series of booby traps to kill loose cats in his neighborhood.',\n",
       "  201),\n",
       " ('You see a boy throwing stones at the cows that are in the local meadow.',\n",
       "  206),\n",
       " ('You see a boy jump the line because his friend is an employee.', 408),\n",
       " ('You see a father forcing his son to become a airplane pilot just like him.',\n",
       "  501),\n",
       " ('You see a trainee disobey a company order to dress professionally and comb his hair.',\n",
       "  610),\n",
       " ('You see a teacher publicly saying that she hopes another school to win the math contest',\n",
       "  702),\n",
       " ('You see a woman intentionally driving her car to run over a squirrel.',\n",
       "  203),\n",
       " ('You see a man saying to his fianc√©e that she has to change to his political party.',\n",
       "  509),\n",
       " ('You see a woman having sex with her deceased husband.', 808),\n",
       " ('You see a boy saying to a woman that she looks like her fat dog.', 105),\n",
       " ('You see someone cheating during a card game with unfamiliar people', 409),\n",
       " ('You see a Brazilian telling foreigner that Brazil is a bad world influence.',\n",
       "  704),\n",
       " ('You see a player publicly yelling with his soccer coach during a decisive match.',\n",
       "  602),\n",
       " ('You see a man whipping his horse because he broke the fence.', 205)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vignettes_list = vignettes_en.split(\"\\n\\n\")\n",
    "\n",
    "scenarios = zip(vignettes_list, validated_codes)\n",
    "\n",
    "random.seed(828)\n",
    "\n",
    "scenarios_to_run = random.choices(list(scenarios), k=20, )\n",
    "# remove duplicates\n",
    "scenarios_to_run = list(set(scenarios_to_run))\n",
    "\n",
    "scenarios_to_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure MFV GPT 3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "for scenario in scenarios_to_run[10:]:\n",
    "    print(f\"Running scenario {scenario[1]}\")\n",
    "    df = single_scenario_generation(scenario, model, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reprocessing files\n",
    "from pathlib import Path\n",
    "from helpers import process_answer\n",
    "import json\n",
    "files = Path(\"data\").glob(\"raw/raw_results_*_2023-08-23*.json\")\n",
    "\n",
    "for f in files:\n",
    "    mfv_code = f.stem.split(\"_\")[2]\n",
    "    print(mfv_code)\n",
    "    now = f.stem.split(\"_\", maxsplit=4)[-1]\n",
    "    fl_content = json.load(f.open())\n",
    "    model = f.stem.split(\"_\")[3]\n",
    "    answers = list()\n",
    "    for i, raw in fl_content:\n",
    "        processed = process_answer(raw)\n",
    "        if len(processed) != 1:\n",
    "            print(f\"WARNING: Answer {i} has {len(processed)} valid answers\")\n",
    "            continue\n",
    "        answers.append((i, processed))\n",
    "    df = pd.DataFrame(answers, columns=[\"gen_id\", \"answer\"])\n",
    "    df[\"mfv_code\"] = mfv_code\n",
    "    df.to_csv(f\"data/results_scenario_{mfv_code}_{model}_{now}.csv\", index=False)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = \"org-bduO767V60bsXkNHgnzwStjp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running scenario 503\n",
      "Running scenario 111\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4\"\n",
    "for scenario in scenarios_to_run:\n",
    "    print(f\"Running scenario {scenario[1]}\")\n",
    "    df = single_scenario_generation(scenario, model, 108)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draft to replicate study 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_system_prompt = \"\"\"\n",
    "Furthermore, you must answer why is the action morally wrong? (Select only the main reason.)\n",
    "\n",
    "    a) It violates norms of harm or care (e.g., unkindness, causing pain to another)\n",
    "\n",
    "    b) It violates norms of fairness or justice (e.g., cheating or reducing equality)\n",
    "\n",
    "    c) It violates norms of loyalty (e.g., betrayal of a group)\n",
    "\n",
    "    d) It violates norms of respecting authority (e.g., subversion, lack of respect for tradition)\n",
    "\n",
    "    e) It violates norms of purity (e.g., degrading or disgusting acts)\n",
    "\n",
    "    f) It violates norms of freedom (e.g., bullying, dominating)\n",
    "\n",
    "    g)It is not morally wrong and does not apply to any of the provided choices\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import openai\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponentia\n",
    "\n",
    "from prompts import system_prompt, alternative_system\n",
    "\n",
    "rep = Path(\".\") / \"mfv material\"\n",
    "\n",
    "DF_PT = pd.read_excel(rep / \"vignettes_pt.xlsx\", sheet_name=0)\n",
    "validated_codes = DF_PT[\"MFV Code\"].to_list()\n",
    "foundations = DF_PT[\"Foundation\"].values\n",
    "\n",
    "original_validated = pd.read_html(\"https://link.springer.com/article/10.3758/s13428-014-0551-2/tables/6\")[0]\n",
    "original_validated[\"mfv_code\"] = [101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,201,202,203,204,205,206,207,208,301,302,303,401,402,403,404,405,406,407,408,409,410,411,412,501,502,503,504,505,506,507,508,509,510,511,601,602,603,604,605,606,607,608,609,610,611,612,613,614,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,801,802,803,804,805,806,807,808,809,810]\n",
    "# query for validated codes\n",
    "original_validated.query(\"mfv_code in @validated_codes\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Scenario</th>\n",
       "      <th>mfv_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Care (p,a)</td>\n",
       "      <td>You see a woman throwing her cat across the ro...</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Care (e)</td>\n",
       "      <td>You see a girl telling a boy that his older br...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Foundation                                           Scenario  mfv_code\n",
       "17  Care (p,a)  You see a woman throwing her cat across the ro...       202\n",
       "13    Care (e)  You see a girl telling a boy that his older br...       114"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_validated.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_response = \"1. 4, b\\n2. 2, g\"\n",
    "\n",
    "def run_foundation_experiment(scenarios, codes, model, **kwargs):\n",
    "    vignettes = \"\\n\".join(scenarios)\n",
    "    new_sys = system_prompt + append_to_system_prompt\n",
    "    msg_hist = [\n",
    "        {\"role\": \"system\", \"content\": new_sys},\n",
    "        {\"role\": \"user\", \"content\": vignettes},\n",
    "    ]\n",
    "    raw_response = chat(\n",
    "        messages=msg_hist,\n",
    "        model=model,\n",
    "        max_tokens=1024,\n",
    "        temperature=1.2,\n",
    "        **kwargs,\n",
    "    )\n",
    "    p = Path(\"data/raw/foundation_validation\")\n",
    "    p.mkdir(exist_ok=True)\n",
    "    with open(p/f\"{model}_{now}.json\", \"w\") as f:\n",
    "        json.dump({\"response\": raw_response, \"scenarios\": scenarios, \"mfv_codes\": codes}, f)\n",
    "    exp_results = process_judgment(raw_response)\n",
    "    df = pd.DataFrame(exp_results, columns=[\"vignette\", \"foundation\"])\n",
    "    df[\"mfv_code\"] = codes\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_judgment(answer, expected=2):\n",
    "    import re\n",
    "    pat = r\"\\d\\.\\s?(\\d+),\\s?([a-g])\"\n",
    "    matches = re.findall(pat, answer)\n",
    "    if len(matches) == 0 or len(matches) != expected:\n",
    "        print(f\"WARNING: Answer has {len(matches)} valid answers\")\n",
    "        return None\n",
    "    else:\n",
    "        return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foundation_validation_generation(n, model):\n",
    "    results = list()\n",
    "    \n",
    "    for i in n:\n",
    "        df = original_validated.sample(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
